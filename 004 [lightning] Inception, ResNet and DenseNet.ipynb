{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1aab6-b03c-47bb-8479-ffa3a90cdb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from types import SimpleNamespace\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "\n",
    "# %matplotlib inline\n",
    "from IPython.display import HTML, display, set_matplotlib_formats\n",
    "from PIL import Image\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_orig()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# PyTorch\n",
    "# Torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad707d8d-6d18-4dc0-9524-a4c3aea9c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = os.environ.get(\"PATH_DATASETS\", \"data/\")\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/ConvNets\")\n",
    "\n",
    "\n",
    "# Function for setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f5f5a-7233-42b2-bca0-c71a969a0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial5/\"\n",
    "# Files to download\n",
    "pretrained_files = [\n",
    "    \"GoogleNet.ckpt\",\n",
    "    \"ResNet.ckpt\",\n",
    "    \"ResNetPreAct.ckpt\",\n",
    "    \"DenseNet.ckpt\",\n",
    "    \"tensorboards/GoogleNet/events.out.tfevents.googlenet\",\n",
    "    \"tensorboards/ResNet/events.out.tfevents.resnet\",\n",
    "    \"tensorboards/ResNetPreAct/events.out.tfevents.resnetpreact\",\n",
    "    \"tensorboards/DenseNet/events.out.tfevents.densenet\",\n",
    "]\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\", 1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(f\"Downloading {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\n",
    "                \"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\",\n",
    "                e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5c47d-6e78-4701-bf3a-347a4d909547",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, download=True)\n",
    "DATA_MEANS = (train_dataset.data / 255.0).mean(axis=(0, 1, 2))\n",
    "DATA_STD = (train_dataset.data / 255.0).std(axis=(0, 1, 2))\n",
    "print(\"Data mean\", DATA_MEANS)\n",
    "print(\"Data std\", DATA_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f57304-91bd-4627-a02c-93d34590d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(DATA_MEANS, DATA_STD)])\n",
    "# For training, we add some augmentation. Networks are too powerful and would overfit.\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop((32, 32), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(DATA_MEANS, DATA_STD),\n",
    "    ]\n",
    ")\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "# We need to do a little trick because the validation set should not use the augmentation.\n",
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
    "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
    "pl.seed_everything(42)\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "pl.seed_everything(42)\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
    "\n",
    "# Loading the test set\n",
    "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(val_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = data.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3812d-4e0b-4ab7-8651-6969c1dd291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, _ = next(iter(train_loader))\n",
    "print(\"Batch mean\", imgs.mean(dim=[0, 2, 3]))\n",
    "print(\"Batch std\", imgs.std(dim=[0, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5feb287-baa9-4035-8061-c7ad2c877f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES = 4\n",
    "images = [train_dataset[idx][0] for idx in range(NUM_IMAGES)]\n",
    "orig_images = [Image.fromarray(train_dataset.data[idx]) for idx in range(NUM_IMAGES)]\n",
    "orig_images = [test_transform(img) for img in orig_images]\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(torch.stack(images + orig_images, dim=0), nrow=4, normalize=True, pad_value=0.5)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Augmentation examples on CIFAR10\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16107e67-909a-4483-8386-271aed93418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa759df-6453-473e-84e1-4858d44d6d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARModule(pl.LightningModule):\n",
    "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model_name - Name of the model/CNN to run. Used for creating the model (see function below)\n",
    "            model_hparams - Hyperparameters for the model, as dictionary.\n",
    "            optimizer_name - Name of the optimizer to use. Currently supported: Adam, SGD\n",
    "            optimizer_hparams - Hyperparameters for the optimizer, as dictionary. This includes learning rate, weight decay, etc.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Exports the hyperparameters to a YAML file, and create \"self.hparams\" namespace\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = create_model(model_name, model_hparams)\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        # Example input for visualizing the graph in Tensorboard\n",
    "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        # Forward function that is run when visualizing the graph\n",
    "        return self.model(imgs)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # We will support Adam or SGD as optimizers.\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            # AdamW is Adam with a correct implementation of weight decay (see here\n",
    "            # for details: https://arxiv.org/pdf/1711.05101.pdf)\n",
    "            optimizer = optim.AdamW(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == \"SGD\":\n",
    "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, f'Unknown optimizer: \"{self.hparams.optimizer_name}\"'\n",
    "\n",
    "        # We will reduce the learning rate by 0.1 after 100 and 150 epochs\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # \"batch\" is the output of the training data loader.\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        # Logs the accuracy per epoch to tensorboard (weighted average over batches)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss  # Return tensor to call \".backward\" on\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs).argmax(dim=-1)\n",
    "        acc = (labels == preds).float().mean()\n",
    "        # By default logs it per epoch (weighted average over batches)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs).argmax(dim=-1)\n",
    "        acc = (labels == preds).float().mean()\n",
    "        # By default logs it per epoch (weighted average over batches), and returns it afterwards\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcb6796-408f-4abd-86b2-2ff7f703c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "\n",
    "def create_model(model_name, model_hparams):\n",
    "    if model_name in model_dict:\n",
    "        return model_dict[model_name](**model_hparams)\n",
    "    else:\n",
    "        assert False, f'Unknown model name \"{model_name}\". Available models are: {str(model_dict.keys())}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f339a3-f587-469d-a827-c297995d39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_fn_by_name = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"leakyrelu\": nn.LeakyReLU, \"gelu\": nn.GELU}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59817225-a5ae-41dd-8719-d383aa111214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, save_name=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model_name - Name of the model you want to run. Is used to look up the class in \"model_dict\"\n",
    "        save_name (optional) - If specified, this name will be used for creating the checkpoint and logging directory.\n",
    "    \"\"\"\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(\n",
    "        default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),  # Where to save models\n",
    "        # We run on a single GPU (if possible)\n",
    "        gpus=1 if str(device) == \"cuda:0\" else 0,\n",
    "        # How many epochs to train for if no patience is set\n",
    "        max_epochs=180,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(\n",
    "                save_weights_only=True, mode=\"max\", monitor=\"val_acc\"\n",
    "            ),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
    "            LearningRateMonitor(\"epoch\"),\n",
    "        ],  # Log learning rate every epoch\n",
    "        progress_bar_refresh_rate=1,\n",
    "    )  # In case your notebook crashes due to the progress bar, consider increasing the refresh rate\n",
    "    trainer.logger._log_graph = True  # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        # Automatically loads the model with the saved hyperparameters\n",
    "        model = CIFARModule.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)  # To be reproducable\n",
    "        model = CIFARModule(model_name=model_name, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = CIFARModule.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path\n",
    "        )  # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, test_dataloaders=val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_dataloaders=test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
    "\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0edaa4-ff08-4056-8438-016f87ef6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_red: dict, c_out: dict, act_fn):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Number of input feature maps from the previous layers\n",
    "            c_red - Dictionary with keys \"3x3\" and \"5x5\" specifying the output of the dimensionality reducing 1x1 convolutions\n",
    "            c_out - Dictionary with keys \"1x1\", \"3x3\", \"5x5\", and \"max\"\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 1x1 convolution branch\n",
    "        self.conv_1x1 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out[\"1x1\"], kernel_size=1), nn.BatchNorm2d(c_out[\"1x1\"]), act_fn()\n",
    "        )\n",
    "\n",
    "        # 3x3 convolution branch\n",
    "        self.conv_3x3 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_red[\"3x3\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_red[\"3x3\"]),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_red[\"3x3\"], c_out[\"3x3\"], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(c_out[\"3x3\"]),\n",
    "            act_fn(),\n",
    "        )\n",
    "\n",
    "        # 5x5 convolution branch\n",
    "        self.conv_5x5 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_red[\"5x5\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_red[\"5x5\"]),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_red[\"5x5\"], c_out[\"5x5\"], kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(c_out[\"5x5\"]),\n",
    "            act_fn(),\n",
    "        )\n",
    "\n",
    "        # Max-pool branch\n",
    "        self.max_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
    "            nn.Conv2d(c_in, c_out[\"max\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_out[\"max\"]),\n",
    "            act_fn(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1x1 = self.conv_1x1(x)\n",
    "        x_3x3 = self.conv_3x3(x)\n",
    "        x_5x5 = self.conv_5x5(x)\n",
    "        x_max = self.max_pool(x)\n",
    "        x_out = torch.cat([x_1x1, x_3x3, x_5x5, x_max], dim=1)\n",
    "        return x_out\n",
    "        \n",
    "# from model.GoogleNet import GoogleNet\n",
    "class GoogleNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, act_fn_name=\"relu\", **kwargs):\n",
    "        super().__init__()\n",
    "        self.hparams = SimpleNamespace(\n",
    "            num_classes=num_classes, act_fn_name=act_fn_name, act_fn=act_fn_by_name[act_fn_name]\n",
    "        )\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "\n",
    "    def _create_network(self):\n",
    "        # A first convolution on the original image to scale up the channel size\n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), self.hparams.act_fn()\n",
    "        )\n",
    "        # Stacking inception blocks\n",
    "        self.inception_blocks = nn.Sequential(\n",
    "            InceptionBlock(\n",
    "                64,\n",
    "                c_red={\"3x3\": 32, \"5x5\": 16},\n",
    "                c_out={\"1x1\": 16, \"3x3\": 32, \"5x5\": 8, \"max\": 8},\n",
    "                act_fn=self.hparams.act_fn,\n",
    "            ),\n",
    "            InceptionBlock(\n",
    "                64,\n",
    "                c_red={\"3x3\": 32, \"5x5\": 16},\n",
    "                c_out={\"1x1\": 24, \"3x3\": 48, \"5x5\": 12, \"max\": 12},\n",
    "                act_fn=self.hparams.act_fn,\n",
    "            ),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),  # 32x32 => 16x16\n",
    "            InceptionBlock(\n",
    "                96,\n",
    "                c_red={\"3x3\": 32, \"5x5\": 16},\n",
    "                c_out={\"1x1\": 24, \"3x3\": 48, \"5x5\": 12, \"max\": 12},\n",
    "                act_fn=self.hparams.act_fn,\n",
    "            ),\n",
    "            InceptionBlock(\n",
    "                96,\n",
    "                c_red={\"3x3\": 32, \"5x5\": 16},\n",
    "                c_out={\"1x1\": 16, \"3x3\": 48, \"5x5\": 16, \"max\": 16},\n",
    "                act_fn=self.hparams.act_fn,\n",
    "            ),\n",
    "            InceptionBlock(\n",
    "                96,\n",
    "                c_red={\"3x3\": 32, \"5x5\": 16},\n",
    "                c_out={\"1x1\": 16, \"3x3\": 48, \"5x5\": 16, \"max\": 16},\n",
    "                act_fn=self.hparams.act_fn,\n",
    "            ),\n",
    "            InceptionBlock(\n",
    "                96,\n",
    "                c_red={\"3x3\": 32, \"5x5\": 16},\n",
    "                c_out={\"1x1\": 32, \"3x3\": 48, \"5x5\": 24, \"max\": 24},\n",
    "                act_fn=self.hparams.act_fn,\n",
    "            ),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),  # 16x16 => 8x8\n",
    "            InceptionBlock(\n",
    "                128,\n",
    "                c_red={\"3x3\": 48, \"5x5\": 16},\n",
    "                c_out={\"1x1\": 32, \"3x3\": 64, \"5x5\": 16, \"max\": 16},\n",
    "                act_fn=self.hparams.act_fn,\n",
    "            ),\n",
    "            InceptionBlock(\n",
    "                128,\n",
    "                c_red={\"3x3\": 48, \"5x5\": 16},\n",
    "                c_out={\"1x1\": 32, \"3x3\": 64, \"5x5\": 16, \"max\": 16},\n",
    "                act_fn=self.hparams.act_fn,\n",
    "            ),\n",
    "        )\n",
    "        # Mapping to classification output\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(128, self.hparams.num_classes)\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        # Based on our discussion in Tutorial 4, we should initialize the\n",
    "        # convolutions according to the activation function\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=self.hparams.act_fn_name)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_net(x)\n",
    "        x = self.inception_blocks(x)\n",
    "        x = self.output_net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_dict[\"GoogleNet\"] = GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dced773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.GoogleNet import GoogleNet\n",
    "model_dict[\"GoogleNet\"] = GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c15ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "googlenet_model, googlenet_results = train_model(\n",
    "    model_name=\"GoogleNet\",\n",
    "    model_hparams={\"num_classes\": 10, \"act_fn_name\": \"relu\"},\n",
    "    optimizer_name=\"Adam\",\n",
    "    optimizer_hparams={\"lr\": 1e-3, \"weight_decay\": 1e-4},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9958b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GoogleNet Results\", googlenet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorboard\n",
    "# %load_ext tensorboard\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec53194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens tensorboard in notebook. Adjust the path to your CHECKPOINT_PATH!\n",
    "# %tensorboard --logdir ./saved_models/ConvNets/tensorboards/GoogleNet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Number of input features\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "            subsample - If True, we want to apply a stride inside the block and reduce the output shape by 2 in height and width\n",
    "            c_out - Number of output features. Note that this is only relevant if subsample is True, as otherwise, c_out = c_in\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if not subsample:\n",
    "            c_out = c_in\n",
    "\n",
    "        # Network representing F\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2, bias=False\n",
    "            ),  # No bias needed as the Batch Norm handles it\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "        )\n",
    "\n",
    "        # 1x1 convolution with stride 2 means we take the upper left value, and transform it to new output size\n",
    "        self.downsample = nn.Conv2d(c_in, c_out, kernel_size=1, stride=2) if subsample else None\n",
    "        self.act_fn = act_fn()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        out = z + x\n",
    "        out = self.act_fn(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bfe804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActResNetBlock(nn.Module):\n",
    "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Number of input features\n",
    "            act_fn - Activation class constructor (e.g. nn.ReLU)\n",
    "            subsample - If True, we want to apply a stride inside the block and reduce the output shape by 2 in height and width\n",
    "            c_out - Number of output features. Note that this is only relevant if subsample is True, as otherwise, c_out = c_in\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if not subsample:\n",
    "            c_out = c_in\n",
    "\n",
    "        # Network representing F\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False),\n",
    "        )\n",
    "\n",
    "        # 1x1 convolution needs to apply non-linearity as well as not done on skip connection\n",
    "        self.downsample = (\n",
    "            nn.Sequential(nn.BatchNorm2d(c_in), act_fn(), nn.Conv2d(c_in, c_out, kernel_size=1, stride=2, bias=False))\n",
    "            if subsample\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        out = z + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55005fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_blocks_by_name = {\"ResNetBlock\": ResNetBlock, \"PreActResNetBlock\": PreActResNetBlock}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes=10,\n",
    "        num_blocks=[3, 3, 3],\n",
    "        c_hidden=[16, 32, 64],\n",
    "        act_fn_name=\"relu\",\n",
    "        block_name=\"ResNetBlock\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            num_classes - Number of classification outputs (10 for CIFAR10)\n",
    "            num_blocks - List with the number of ResNet blocks to use. The first block of each group uses downsampling, except the first.\n",
    "            c_hidden - List with the hidden dimensionalities in the different blocks. Usually multiplied by 2 the deeper we go.\n",
    "            act_fn_name - Name of the activation function to use, looked up in \"act_fn_by_name\"\n",
    "            block_name - Name of the ResNet block, looked up in \"resnet_blocks_by_name\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert block_name in resnet_blocks_by_name\n",
    "        self.hparams = SimpleNamespace(\n",
    "            num_classes=num_classes,\n",
    "            c_hidden=c_hidden,\n",
    "            num_blocks=num_blocks,\n",
    "            act_fn_name=act_fn_name,\n",
    "            act_fn=act_fn_by_name[act_fn_name],\n",
    "            block_class=resnet_blocks_by_name[block_name],\n",
    "        )\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "\n",
    "    def _create_network(self):\n",
    "        c_hidden = self.hparams.c_hidden\n",
    "\n",
    "        # A first convolution on the original image to scale up the channel size\n",
    "        if self.hparams.block_class == PreActResNetBlock:  # => Don't apply non-linearity on output\n",
    "            self.input_net = nn.Sequential(nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1, bias=False))\n",
    "        else:\n",
    "            self.input_net = nn.Sequential(\n",
    "                nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(c_hidden[0]),\n",
    "                self.hparams.act_fn(),\n",
    "            )\n",
    "\n",
    "        # Creating the ResNet blocks\n",
    "        blocks = []\n",
    "        for block_idx, block_count in enumerate(self.hparams.num_blocks):\n",
    "            for bc in range(block_count):\n",
    "                # Subsample the first block of each group, except the very first one.\n",
    "                subsample = bc == 0 and block_idx > 0\n",
    "                blocks.append(\n",
    "                    self.hparams.block_class(\n",
    "                        c_in=c_hidden[block_idx if not subsample else (block_idx - 1)],\n",
    "                        act_fn=self.hparams.act_fn,\n",
    "                        subsample=subsample,\n",
    "                        c_out=c_hidden[block_idx],\n",
    "                    )\n",
    "                )\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "        # Mapping to classification output\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(), nn.Linear(c_hidden[-1], self.hparams.num_classes)\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        # Based on our discussion in Tutorial 4, we should initialize the convolutions according to the activation function\n",
    "        # Fan-out focuses on the gradient distribution, and is commonly used in ResNets\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=self.hparams.act_fn_name)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_net(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.output_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e90a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"ResNet\"] = ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model, resnet_results = train_model(\n",
    "    model_name=\"ResNet\",\n",
    "    model_hparams={\"num_classes\": 10, \"c_hidden\": [16, 32, 64], \"num_blocks\": [3, 3, 3], \"act_fn_name\": \"relu\"},\n",
    "    optimizer_name=\"SGD\",\n",
    "    optimizer_hparams={\"lr\": 0.1, \"momentum\": 0.9, \"weight_decay\": 1e-4},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnetpreact_model, resnetpreact_results = train_model(\n",
    "    model_name=\"ResNet\",\n",
    "    model_hparams={\n",
    "        \"num_classes\": 10,\n",
    "        \"c_hidden\": [16, 32, 64],\n",
    "        \"num_blocks\": [3, 3, 3],\n",
    "        \"act_fn_name\": \"relu\",\n",
    "        \"block_name\": \"PreActResNetBlock\",\n",
    "    },\n",
    "    optimizer_name=\"SGD\",\n",
    "    optimizer_hparams={\"lr\": 0.1, \"momentum\": 0.9, \"weight_decay\": 1e-4},\n",
    "    save_name=\"ResNetPreAct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd063767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens tensorboard in notebook. Adjust the path to your CHECKPOINT_PATH! Feel free to change \"ResNet\" to \"ResNetPreAct\"\n",
    "%tensorboard --logdir ./saved_models/tensorboards/ResNet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04397da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2de7f4319369907ee8489a4f9fa2d3d729739eb508fbf56af42ccf1e5eb66bfe"
  },
  "kernelspec": {
   "display_name": "[py38::pytorch_lightning]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
